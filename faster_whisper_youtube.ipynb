{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barkahss/DaProfiler/blob/main/faster_whisper_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with Faster Whisper**\n",
        "\n",
        "\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/lewangdev/whisper-youtube/blob/main/faster_whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/lewangdev/faster_whisper_youtube)](https://github.com/lewangdev/faster_whisper_youtube)\n",
        "\n",
        "\n",
        "[faster-whisper](https://github.com/guillaumekln/faster-whisper) is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models.\n",
        "\n",
        "This implementation is up to 4 times faster than openai/whisper for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Faster Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** ğŸ•µï¸\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QshUbLqpX7L4",
        "cellView": "form",
        "outputId": "c780d185-c1eb-49d8-b601-9b8e6f9b92d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-078172d2-0b0b-3201-4454-a83ecddc0fb0)\n",
            "Sat May  3 23:12:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "outputId": "8d9eeffa-604d-4fdc-e80e-e5e720742a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.30.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.13.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Downloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-14.3.0 coloredlogs-15.0.1 ctranslate2-4.6.0 faster-whisper-1.1.1 humanfriendly-10.0 onnxruntime-1.21.1\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.4.30-py3-none-any.whl.metadata (173 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.4.30-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.4.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Install libraries** ğŸ—ï¸\n",
        "#@markdown This cell will take a little while to download several libraries, including Faster Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install faster-whisper\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "from faster_whisper import WhisperModel\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive ğŸ’¾\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Faster Whisper Youtube\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** ğŸ§ \n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~0.8 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1.0 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~1.4 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~2.7 GB     |      ~2x       |\n",
        "#@markdown | large-v1  |   1550 M   |        N/A         |      `large-v1`       |    ~4.3 GB     |       1x       |\n",
        "#@markdown | large-v2  |   1550 M   |        N/A         |      `large-v2`       |    ~4.3 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "model_size = 'large-v2' #@param ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large-v1', 'large-v2']\n",
        "device_type = \"cuda\" #@param {type:\"string\"} ['cuda', 'cpu']\n",
        "compute_type = \"float16\" #@param {type:\"string\"} ['float16', 'int8_float16', 'int8']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "model = WhisperModel(model_size, device=device_type, compute_type=compute_type)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TMhrSq_GZ6kA",
        "outputId": "5c4c551c-121d-4edc-ba18-1d36267bf8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311,
          "referenced_widgets": [
            "bb7759840d204dc88dbec71c38738e24",
            "9089b249d5f14f09ac267c3c69c112db",
            "da3c06ff008542498053217a08c5ddfa",
            "984ad981f9b64d758e625c41dbf2280c",
            "58af80b1c71c48e29078bea4af39d5b4",
            "258fa3c867764792ac0592aa1190468f",
            "f999179a208a4d5598077b0940a35584",
            "17be5116bb3e4fc3ba8a2f855006ea4f",
            "92677ab9d0b54e058c78f6a4877003e9",
            "8eb1b7e66ad4442e8ce7f4d9ddae6560",
            "4e106387bff64429a3bf2a8df263ad4d",
            "94b1268a92964c1c83f7bfe1e0b3dbef",
            "c43197d396584f44aaef8b2daf10b352",
            "b40a2e2c6e8345999b7f9ed68a8124be",
            "e76388524b374b3ebdb0b047d550c22a",
            "e7e6a06636d44cab97dc71e860a542e6",
            "7adf384ef98b48ed85fb37052bfb0a24",
            "19cc79dd71c34a319606fc1834f37368",
            "9fb2e424ccae458d9e3de92e12f6e8f6",
            "956bfbdcd8d74a33be8913102eb7a480",
            "bc9f3f9d077b4e738e68b2601e3a390d",
            "cc021f74faca4bb1965dead0ec8818e4",
            "bbdc40de4696460989d149dd85988ac7",
            "e5b11af3c6474d2ba5865fc0ac92d1a0",
            "a2a1694a37664132a448610f0922f73f",
            "0d0de53c6599467d97166effc9795179",
            "4447087ff28d427eb30a654c438d850b",
            "f7896fa01c08497cba97982c01df7c37",
            "a8ac426e18bf4afeb2df764c50448ffd",
            "79f1c099d9234aaab6002f14330b0a30",
            "2f261793ba73484a84a85c92c9aae4c3",
            "8f90a80724964946b7c233866859c346",
            "84206d064d9a4116aae01b9a1d823b3f",
            "376d9f7b1e4044218f662b4f8cdda836",
            "0751d2b5d3f344a1ba719241d16b9c65",
            "df633e608ada4c7e8b8238cb221db739",
            "76753b02dce24351af3e2296fb3f5e0c",
            "2d24ffabd2f8417ba3f6b039b3014ab9",
            "a7d46474f7c24285a818352fdbc12a76",
            "b6401a11ba43431fa04a8dbd56af5438",
            "9f8907c806714278be338e3f9a78b132",
            "6fdba297b1b24f06a2b9c5767b64a91e",
            "46d52861e235488b82aa0c6aa7c0fdbc",
            "bc12ffae6ad943b6aed3c2251a24352f"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb7759840d204dc88dbec71c38738e24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94b1268a92964c1c83f7bfe1e0b3dbef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbdc40de4696460989d149dd85988ac7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "376d9f7b1e4044218f662b4f8cdda836"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** ğŸ“º\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://youtu.be/45WPU7P-1QQ?si=pcJZxSNJx1mRwpV1\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # â„¹ï¸ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "cellView": "form",
        "outputId": "ff138950-30be-4975-c1cc-b15cc137f6e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/45WPU7P-1QQ?si=pcJZxSNJx1mRwpV1\n",
            "[youtube] 45WPU7P-1QQ: Downloading webpage\n",
            "[youtube] 45WPU7P-1QQ: Downloading tv client config\n",
            "[youtube] 45WPU7P-1QQ: Downloading player aa3fc80b-main\n",
            "[youtube] 45WPU7P-1QQ: Downloading tv player API JSON\n",
            "[youtube] 45WPU7P-1QQ: Downloading ios player API JSON\n",
            "[youtube] 45WPU7P-1QQ: Downloading m3u8 information\n",
            "[info] 45WPU7P-1QQ: Downloading 1 format(s): 140\n",
            "[download] Destination: 45WPU7P-1QQ.m4a\n",
            "[download] 100% of   10.96MiB in 00:00:00 at 17.16MiB/s  \n",
            "[FixupM4a] Correcting container of \"45WPU7P-1QQ.m4a\"\n",
            "[ExtractAudio] Destination: 45WPU7P-1QQ.wav\n",
            "Deleting original file 45WPU7P-1QQ.m4a (pass -k to keep)\n",
            "[youtube] Extracting URL: https://youtu.be/45WPU7P-1QQ?si=pcJZxSNJx1mRwpV1\n",
            "[youtube] 45WPU7P-1QQ: Downloading webpage\n",
            "[youtube] 45WPU7P-1QQ: Downloading tv client config\n",
            "[youtube] 45WPU7P-1QQ: Downloading tv player API JSON\n",
            "[youtube] 45WPU7P-1QQ: Downloading ios player API JSON\n",
            "[youtube] 45WPU7P-1QQ: Downloading m3u8 information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seconds_to_time_format(s):\n",
        "    # Convert seconds to hours, minutes, seconds, and milliseconds\n",
        "    hours = s // 3600\n",
        "    s %= 3600\n",
        "    minutes = s // 60\n",
        "    s %= 60\n",
        "    seconds = s // 1\n",
        "    milliseconds = round((s % 1) * 1000)\n",
        "\n",
        "    # Return the formatted string\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(milliseconds):03d}\"\n",
        "\n",
        "#@markdown # **Run the model** ğŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown #### Language\n",
        "language = \"en\" #@param [\"auto\", \"en\", \"zh\", \"ja\", \"fr\", \"de\"] {allow-input: true}\n",
        "#@markdown #### initial prompt\n",
        "initial_prompt = \"Please do not translate, only transcription be allowed.  Here are some English words you may need: Cindy. And Chinese words: \\u7206\\u7834\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Word-level timestamps\n",
        "word_level_timestamps = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### VAD filter\n",
        "vad_filter = True #@param {type:\"boolean\"}\n",
        "vad_filter_min_silence_duration_ms = 50 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Output(Default is srt, txt if `text_only` be checked )\n",
        "text_only = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                  language=None if language == \"auto\" else language,\n",
        "                                  initial_prompt=initial_prompt,\n",
        "                                  word_timestamps=word_level_timestamps,\n",
        "                                  vad_filter=vad_filter,\n",
        "                                  vad_parameters=dict(min_silence_duration_ms=vad_filter_min_silence_duration_ms))\n",
        "\n",
        "display(Markdown(f\"Detected language '{info.language}' with probability {info.language_probability}\"))\n",
        "\n",
        "ext_name = '.txt' if text_only else \".srt\"\n",
        "transcript_file_name = video_path_local.stem + ext_name\n",
        "sentence_idx = 1\n",
        "with open(transcript_file_name, 'w') as f:\n",
        "  for segment in segments:\n",
        "    if word_level_timestamps:\n",
        "      for word in segment.words:\n",
        "        ts_start = seconds_to_time_format(word.start)\n",
        "        ts_end = seconds_to_time_format(word.end)\n",
        "        print(f\"[{ts_start} --> {ts_end}] {word.word}\")\n",
        "        if not text_only:\n",
        "          f.write(f\"{sentence_idx}\\n\")\n",
        "          f.write(f\"{ts_start} --> {ts_end}\\n\")\n",
        "          f.write(f\"{word.word}\\n\\n\")\n",
        "        else:\n",
        "          f.write(f\"{word.word}\")\n",
        "        f.write(\"\\n\")\n",
        "        sentence_idx = sentence_idx + 1\n",
        "    else:\n",
        "      ts_start = seconds_to_time_format(segment.start)\n",
        "      ts_end = seconds_to_time_format(segment.end)\n",
        "      print(f\"[{ts_start} --> {ts_end}] {segment.text}\")\n",
        "      if not text_only:\n",
        "        f.write(f\"{sentence_idx}\\n\")\n",
        "        f.write(f\"{ts_start} --> {ts_end}\\n\")\n",
        "        f.write(f\"{segment.text.strip()}\\n\\n\")\n",
        "      else:\n",
        "        f.write(f\"{segment.text.strip()}\\n\")\n",
        "      sentence_idx = sentence_idx + 1\n",
        "\n",
        "try:\n",
        "  shutil.copy(video_path_local.parent / transcript_file_name,\n",
        "            drive_whisper_path / transcript_file_name\n",
        "  )\n",
        "  display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "except:\n",
        "  display(Markdown(f\"**Transcript file created: {video_path_local.parent / transcript_file_name}**\"))\n"
      ],
      "metadata": {
        "id": "Ad6n1m4deAHp",
        "collapsed": true,
        "outputId": "9c19f538-e918-4413-c4a2-b58630b981b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Detected language 'en' with probability 1"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00:00,480 --> 00:00:07,120]  Hey Flowgrammers! N8n just dropped a native MCP server and MCP client node.\n",
            "[00:00:08,350 --> 00:00:14,110]  In this video I'm going to quickly explain what MCP is and why it might be relevant for you,\n",
            "[00:00:14,110 --> 00:00:20,030]  and then we're going to take a look at how to use the new MCP server and MCP client nodes within\n",
            "[00:00:20,030 --> 00:00:24,350]  N8n. So if you already know what MCP is, use the chapters to skip ahead.\n",
            "[00:00:27,940 --> 00:00:34,100]  MCP is an abbreviation. It stands for Model Context Protocol. It was designed and released\n",
            "[00:00:34,100 --> 00:00:40,020]  by Anthropic, creator of the popular Claude models, including Sonnet 3.7, and it's an attempt\n",
            "[00:00:40,020 --> 00:00:45,940]  to standardize the communication that LLMs do with other systems. Since its release near the end of\n",
            "[00:00:45,940 --> 00:00:52,020]  2024, it's gotten quite a lot of adoption. In particular, OpenAI has signed on to support the\n",
            "[00:00:52,020 --> 00:00:57,940]  standard, and various SaaS apps and other desktop tools even are bringing support for MCP. The\n",
            "[00:00:57,940 --> 00:01:02,900]  reason that's important, of course, is the utility a protocol can provide really hinges on its\n",
            "[00:01:02,900 --> 00:01:07,860]  network effect, right? If people aren't adopting it, no one's going to use it. So for example,\n",
            "[00:01:07,860 --> 00:01:13,140]  SD cards were useful because everyone used SD cards. Sony's memory stick, that's a different\n",
            "[00:01:13,140 --> 00:01:18,580]  story. There's plenty of videos that will give you a really deep technical dive into what MCP is,\n",
            "[00:01:18,580 --> 00:01:23,220]  so I'm just going to keep it really high level and go over the key conceptual entities in the\n",
            "[00:01:23,220 --> 00:01:30,100]  MCP framework. The first relevant entity is the MCP host. This is your LLM powered app that\n",
            "[00:01:30,100 --> 00:01:35,940]  basically needs context from the outside world, from outside systems, or to interact with those\n",
            "[00:01:35,940 --> 00:01:42,260]  systems, i.e. use them as tools. So Claude desktop would be an example of an MCP host. The next one\n",
            "[00:01:42,340 --> 00:01:48,740]  is the MCP client. This manages the connections between hosts and servers, which brings us to\n",
            "[00:01:48,740 --> 00:01:54,900]  the MCP server, which is typically a lightweight program that exposes various functionality and\n",
            "[00:01:54,900 --> 00:01:59,220]  actions basically that you can take in that server. To my understanding right now, and I think a lot of\n",
            "[00:01:59,220 --> 00:02:04,100]  us are still wrapping our heads around this, I like to think of the MCP server as basically an\n",
            "[00:02:04,100 --> 00:02:10,580]  API and docs that's sent along to the MCP host, which is your LLM. And this way it gets a single\n",
            "[00:02:10,580 --> 00:02:16,340]  package, it knows what it can use, how to use it, and then the ability to use it as well. So it's an\n",
            "[00:02:16,340 --> 00:02:22,180]  actionable API essentially in the context of an LLM. Now before we get into the cool new MCP\n",
            "[00:02:22,180 --> 00:02:28,260]  functionality within NNN, I do think it's important to note that MCP is a new protocol and not everyone\n",
            "[00:02:28,260 --> 00:02:32,340]  in the engineering community is happy with it. Which if we look at the case of microservices,\n",
            "[00:02:32,340 --> 00:02:35,940]  for example, you're never going to get all engineers to agree on something. But the good\n",
            "[00:02:35,940 --> 00:02:40,580]  argument that I've heard essentially was, look, we've got a lot of already well-established\n",
            "[00:02:40,580 --> 00:02:45,540]  protocols for computers to interact with each other. For example, RESTful APIs. So why did we\n",
            "[00:02:45,540 --> 00:02:50,740]  need to go create a new protocol? Which is a fair argument. Nonetheless, it's being adopted across\n",
            "[00:02:50,740 --> 00:02:55,940]  the AI industry. Again, big players are adopting this. The NNN team has added it to make sure that\n",
            "[00:02:55,940 --> 00:03:01,220]  the NNN community can be on the bleeding edge and exploring how these new protocols could help us\n",
            "[00:03:01,220 --> 00:03:06,260]  do more. And I think the big question that we're all asking, and we'd love the community help on,\n",
            "[00:03:06,260 --> 00:03:14,420]  is why is MCP not just another REST API? What can MCP allow you to do that we couldn't do before\n",
            "[00:03:14,420 --> 00:03:19,140]  in the context of NNN workflows? And I think that's a perfect segue to jump into the NNN\n",
            "[00:03:19,140 --> 00:03:24,260]  canvas and check out the new MCP server and MCP client nodes within NNN.\n",
            "[00:03:24,580 --> 00:03:31,230]  I'm going to first show you how to use MCP server because it allows your cloud desktop or any other\n",
            "[00:03:31,230 --> 00:03:36,590]  MCP host to access the hundreds of different tools and custom workflows that you can build\n",
            "[00:03:36,590 --> 00:03:40,830]  inside of NNN. I think it's going to be super, super powerful. So from a blank workflow,\n",
            "[00:03:40,830 --> 00:03:47,070]  let's add our first step. Since the MCP server is something that our MCP host is going to consume,\n",
            "[00:03:47,070 --> 00:03:52,990]  in NNN, it's going to be a trigger. So let's search for MCP. And then we see the MCP host\n",
            "[00:03:52,990 --> 00:03:58,270]  MCP, and then we see the MCP server trigger in here. Let's click to add that to the canvas.\n",
            "[00:03:58,270 --> 00:04:02,830]  It doesn't have any parameters right now. This isn't beta. We're going to add some of the other\n",
            "[00:04:02,830 --> 00:04:07,950]  things that MCP supports, but the NNN team wanted to get this out, get your feedback on this so we\n",
            "[00:04:07,950 --> 00:04:13,470]  can iterate on it faster for you. So if you do have any feedback, make sure to go to community.nnn.io\n",
            "[00:04:13,470 --> 00:04:18,510]  and drop a comment there. So we've added the MCP server. What we need to now do is give it some\n",
            "[00:04:18,510 --> 00:04:23,950]  tools that then our host can access. For this first example, let's just add a really basic one\n",
            "[00:04:23,950 --> 00:04:28,910]  and add the calculator tool because LLMs are not that good at doing math. So we'd rather have them\n",
            "[00:04:28,910 --> 00:04:33,390]  use a tool for that. So let's do that. And let's save this. Now you're going to want to make sure\n",
            "[00:04:33,390 --> 00:04:38,430]  that your work was activated. So activate that. Next, we need to go over to Claude or whatever\n",
            "[00:04:38,430 --> 00:04:42,110]  your MCP host is. Again, I'm going to use the Claude desktop app here. If you don't have the\n",
            "[00:04:42,110 --> 00:04:46,510]  Claude desktop app, the dependencies you're going to need to run what we're doing here today is to\n",
            "[00:04:46,510 --> 00:04:50,590]  download the Claude desktop app, have an Anthropic account. You're also going to have to have Node\n",
            "[00:04:50,590 --> 00:04:56,990]  installed because Claude desktop today doesn't support communicating with MCP clients through\n",
            "[00:04:56,990 --> 00:05:01,470]  SSE, which is what the end-to-end team supports in the MCP trigger. There's a lot of technical\n",
            "[00:05:01,470 --> 00:05:05,470]  reasons why the end-to-end team chose that, but you are going to have to use a gateway. Meanwhile,\n",
            "[00:05:05,470 --> 00:05:09,630]  that's going to basically do that SSE part and make sure that Claude can communicate with your\n",
            "[00:05:09,630 --> 00:05:14,590]  MCP trigger. Once you open up Claude desktop, make sure that you're in developer mode. To do that,\n",
            "[00:05:14,590 --> 00:05:19,470]  from the top menu, there's going to be a help section and it's going to say enable developer\n",
            "[00:05:19,470 --> 00:05:23,550]  mode. I already did that and I can't find a way to undo that, but make sure that you're in Claude\n",
            "[00:05:23,550 --> 00:05:27,870]  developer mode and ask your favorite LLM if you don't know how to do that. All right, so from\n",
            "[00:05:27,870 --> 00:05:33,390]  Claude, open the settings and then here we're going to go down to the developer section and we want to\n",
            "[00:05:33,390 --> 00:05:38,990]  click this edit config button. That's going to open up a folder and in here we see this JSON file,\n",
            "[00:05:38,990 --> 00:05:42,910]  so you're going to want to open that with your favorite text editor. In this case, I'm using\n",
            "[00:05:42,910 --> 00:05:46,990]  Sublime. Unless you've been tinkering with MCP before, this page is going to be blank and you're\n",
            "[00:05:46,990 --> 00:05:52,750]  going to want to paste in this. A few things to call out, I am using super gateway here. This is\n",
            "[00:05:52,750 --> 00:05:58,190]  going to allow Claude to communicate with our MCP trigger over SSE protocol because Claude doesn't\n",
            "[00:05:58,190 --> 00:06:02,990]  natively support that right now, so that is a dependency. And one pro tip here, if this is\n",
            "[00:06:02,990 --> 00:06:07,550]  failing, if you're getting errors when you're trying this, try to run this command manually\n",
            "[00:06:07,550 --> 00:06:13,710]  in your terminal. So npx and then pass this arguments super gateway SSE and then swap in\n",
            "[00:06:13,710 --> 00:06:18,190]  your webhook URL. Because I was having some errors around this, it was failing in terminal and I\n",
            "[00:06:18,190 --> 00:06:22,510]  actually had some permission errors around node itself. I fixed that and then it was working. So\n",
            "[00:06:22,510 --> 00:06:26,990]  if you're getting some errors around that, first try to run this command manually in your terminal.\n",
            "[00:06:26,990 --> 00:06:31,790]  Okay, the structure here is we've got MCP servers. We can have many of these MCP servers, right? And\n",
            "[00:06:31,790 --> 00:06:38,190]  in this case, we need to now paste in that webhook URL. Let's go back to my workflow. Let's open that\n",
            "[00:06:38,190 --> 00:06:44,590]  up. Let's get the webhook URL, copy that production URL. Let's copy that and let's paste that in here.\n",
            "[00:06:45,230 --> 00:06:49,790]  So this is all good here. We're going to save this. Now we do need to restart Claude. So I'm\n",
            "[00:06:49,790 --> 00:06:56,190]  hitting command Q to close it. We're going to open it back up. It's loaded and we see now we've got\n",
            "[00:06:56,190 --> 00:07:01,790]  one MCP tool available here. And we see that we've got the calculator tool and it's from the\n",
            "[00:07:01,790 --> 00:07:06,350]  NN server. Now we could have called the server calculator as well. But let's assume you have\n",
            "[00:07:06,350 --> 00:07:10,510]  like your NN instance and you're going to want to have a few tools that you give Claude access to.\n",
            "[00:07:10,510 --> 00:07:15,390]  So this could be a good way to go do that. Tool is called calculator. Let's see if we can run it.\n",
            "[00:07:18,450 --> 00:07:23,650]  Let's see. Okay, so we get a permission check in here. This is interesting.\n",
            "[00:07:24,370 --> 00:07:28,050]  Nice. It's even showing what arguments it would use. Okay. Let's allow for this chat. Well,\n",
            "[00:07:28,050 --> 00:07:31,730]  this is really cool how it's kind of the UX of how it's showing you how it's interacting with that.\n",
            "[00:07:31,730 --> 00:07:37,490]  Okay. So this is what it responded with. It's 500. Let's go double check that. So in my workflow,\n",
            "[00:07:37,490 --> 00:07:42,850]  I can go over to the executions. Great. This one just ran. Let's just open up the calculator and\n",
            "[00:07:42,850 --> 00:07:49,330]  see. Yep. That's the 500 response query. 50 times 10. Perfect. And so this is just the calculator\n",
            "[00:07:49,330 --> 00:07:54,210]  tool, right? I'm sure Claude even has its own calculator. So maybe that's not as interesting.\n",
            "[00:07:54,210 --> 00:07:57,890]  But what I'm trying to show you here is how to get unblocked on setting this up,\n",
            "[00:07:57,890 --> 00:08:02,930]  because actually creating this thing here took me a bit of effort. It was a few headbanging moments.\n",
            "[00:08:02,930 --> 00:08:06,290]  So hopefully you avoid that. If you're watching this on YouTube, I'm going to have this in the\n",
            "[00:08:06,290 --> 00:08:09,970]  description. If you're watching this somewhere else, get to the YouTube video. I will have\n",
            "[00:08:09,970 --> 00:08:14,850]  this snippet here for you. And just to call out again, we can add many different tools here.\n",
            "[00:08:14,850 --> 00:08:19,170]  There's all various vector stores you could use. So your Claude desktop or whatever host you're\n",
            "[00:08:19,170 --> 00:08:24,130]  using can be a knowledge rag assistant already connecting with lots of different apps and\n",
            "[00:08:24,130 --> 00:08:28,850]  services. But some of the really cool ones to call out, I think, where NNN is going to be really\n",
            "[00:08:28,850 --> 00:08:36,370]  interesting is again, the call NNN workflow tool, which is going to allow your MCP host to interact\n",
            "[00:08:36,370 --> 00:08:42,050]  with any arbitrary NNN workflow. That itself could be an AI agent. It could be some air-gapped\n",
            "[00:08:42,050 --> 00:08:45,810]  self-hosted enterprise information that's really, really sensitive for you. So that's\n",
            "[00:08:45,810 --> 00:08:54,780]  how you set up the MCP server trigger in NNN. If I click the tool here from my AI agent,\n",
            "[00:08:54,780 --> 00:09:01,660]  let's add that to the canvas MCP, and we'll see the MCP client tool. So let's click to add that.\n",
            "[00:09:01,660 --> 00:09:06,380]  Now we'll set it up in a second, but just to contextualize this, the AI agent in this case\n",
            "[00:09:06,380 --> 00:09:10,780]  is a host, right? As the host, it's going to interact with the client. In the client,\n",
            "[00:09:10,780 --> 00:09:16,460]  we're going to configure the connection basically to the MCP server. So then the AI agents are host,\n",
            "[00:09:16,460 --> 00:09:23,100]  it's using the client to interact with our MCP server. Now, since we just built an MCP server\n",
            "[00:09:23,100 --> 00:09:28,220]  through this MCP trigger in another workflow, let's have our AI agent here interact with that\n",
            "[00:09:28,220 --> 00:09:32,540]  calculator tool. I'll double click on it, and we're going to add a credential to connect with.\n",
            "[00:09:32,540 --> 00:09:38,460]  We'll create a new one. And inside the credential, the SSE endpoint, that's what we need to actually\n",
            "[00:09:38,460 --> 00:09:46,620]  get from our MCP trigger here. So I'll go in here and grab that production URL, paste in our SSE endpoint,\n",
            "[00:09:46,620 --> 00:09:51,340]  and let's save this. And okay, great. We've got a connection test. Now that this is set up, let's\n",
            "[00:09:51,340 --> 00:09:57,340]  close the credential. Since an MCP server can offer multiple tools, we could choose to get all of the\n",
            "[00:09:57,340 --> 00:10:01,900]  tools that that server has available, or we could just select those. So in this case, we can see\n",
            "[00:10:01,900 --> 00:10:06,300]  we've established a connection with the system because it's shown us this calculator here.\n",
            "[00:10:06,300 --> 00:10:11,260]  Perfect. So now let's go back to the workflow canvas, and let's give this a quick test by\n",
            "[00:10:11,260 --> 00:10:22,500]  opening the manual chat. Let's ask it to calculate 15 times 10. Okay, it's used the tool. Let's have\n",
            "[00:10:22,500 --> 00:10:28,830]  a look in the logs here. Yep, it sent the query, and we've got the response. Now let's go over to\n",
            "[00:10:28,830 --> 00:10:35,710]  our trigger here. Let's go in the executions, and we can see that, yep, it also ran. Perfect.\n",
            "[00:10:35,710 --> 00:10:43,230]  That's how you set up an MCP client with MCP servers from an AI agent within N8n.\n",
            "[00:10:46,860 --> 00:10:53,580]  So I just explained what MCP is, how you can set up an MCP server in N8n natively. The same for\n",
            "[00:10:53,580 --> 00:10:59,420]  setting up an MCP tool, which is an MCP client, so that you can connect with other MCP servers.\n",
            "[00:10:59,420 --> 00:11:05,900]  The next step is go update your version of N8n, and go have fun. And if you haven't signed up for\n",
            "[00:11:05,900 --> 00:11:11,900]  N8n yet, make sure to use my coupon code MAX50 after your cloud trial. That's going to give you\n",
            "[00:11:11,900 --> 00:11:16,780]  50% off N8n cloud for a whole year. You can self-host N8n as well, but if you choose our\n",
            "[00:11:16,780 --> 00:11:21,100]  cloud option, my boss is going to be really happy if you go to cloud, of course. I hope you found\n",
            "[00:11:21,100 --> 00:11:25,100]  this video useful. Please do give me some feedback on what you'd like to see more of, or you think I\n",
            "[00:11:25,100 --> 00:11:29,580]  may have missed. I expect this isn't going to be the last video I do on this topic. Thank you so\n",
            "[00:11:29,580 --> 00:11:34,220]  much for watching. I really appreciate it. I'm Max, the original Flow Grammar. You're awesome\n",
            "[00:11:34,220 --> 00:11:37,660]  for watching this video, and happy Flowgramming.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: 45WPU7P-1QQ.srt**"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb7759840d204dc88dbec71c38738e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9089b249d5f14f09ac267c3c69c112db",
              "IPY_MODEL_da3c06ff008542498053217a08c5ddfa",
              "IPY_MODEL_984ad981f9b64d758e625c41dbf2280c"
            ],
            "layout": "IPY_MODEL_58af80b1c71c48e29078bea4af39d5b4"
          }
        },
        "9089b249d5f14f09ac267c3c69c112db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_258fa3c867764792ac0592aa1190468f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f999179a208a4d5598077b0940a35584",
            "value": "vocabulary.txt:â€‡100%"
          }
        },
        "da3c06ff008542498053217a08c5ddfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17be5116bb3e4fc3ba8a2f855006ea4f",
            "max": 459861,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92677ab9d0b54e058c78f6a4877003e9",
            "value": 459861
          }
        },
        "984ad981f9b64d758e625c41dbf2280c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eb1b7e66ad4442e8ce7f4d9ddae6560",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4e106387bff64429a3bf2a8df263ad4d",
            "value": "â€‡460k/460kâ€‡[00:00&lt;00:00,â€‡5.67MB/s]"
          }
        },
        "58af80b1c71c48e29078bea4af39d5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258fa3c867764792ac0592aa1190468f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f999179a208a4d5598077b0940a35584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17be5116bb3e4fc3ba8a2f855006ea4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92677ab9d0b54e058c78f6a4877003e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eb1b7e66ad4442e8ce7f4d9ddae6560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e106387bff64429a3bf2a8df263ad4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94b1268a92964c1c83f7bfe1e0b3dbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43197d396584f44aaef8b2daf10b352",
              "IPY_MODEL_b40a2e2c6e8345999b7f9ed68a8124be",
              "IPY_MODEL_e76388524b374b3ebdb0b047d550c22a"
            ],
            "layout": "IPY_MODEL_e7e6a06636d44cab97dc71e860a542e6"
          }
        },
        "c43197d396584f44aaef8b2daf10b352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7adf384ef98b48ed85fb37052bfb0a24",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_19cc79dd71c34a319606fc1834f37368",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "b40a2e2c6e8345999b7f9ed68a8124be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb2e424ccae458d9e3de92e12f6e8f6",
            "max": 2203239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_956bfbdcd8d74a33be8913102eb7a480",
            "value": 2203239
          }
        },
        "e76388524b374b3ebdb0b047d550c22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9f3f9d077b4e738e68b2601e3a390d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cc021f74faca4bb1965dead0ec8818e4",
            "value": "â€‡2.20M/2.20Mâ€‡[00:00&lt;00:00,â€‡8.85MB/s]"
          }
        },
        "e7e6a06636d44cab97dc71e860a542e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adf384ef98b48ed85fb37052bfb0a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19cc79dd71c34a319606fc1834f37368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fb2e424ccae458d9e3de92e12f6e8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956bfbdcd8d74a33be8913102eb7a480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9f3f9d077b4e738e68b2601e3a390d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc021f74faca4bb1965dead0ec8818e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbdc40de4696460989d149dd85988ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b11af3c6474d2ba5865fc0ac92d1a0",
              "IPY_MODEL_a2a1694a37664132a448610f0922f73f",
              "IPY_MODEL_0d0de53c6599467d97166effc9795179"
            ],
            "layout": "IPY_MODEL_4447087ff28d427eb30a654c438d850b"
          }
        },
        "e5b11af3c6474d2ba5865fc0ac92d1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7896fa01c08497cba97982c01df7c37",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a8ac426e18bf4afeb2df764c50448ffd",
            "value": "config.json:â€‡100%"
          }
        },
        "a2a1694a37664132a448610f0922f73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f1c099d9234aaab6002f14330b0a30",
            "max": 2796,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f261793ba73484a84a85c92c9aae4c3",
            "value": 2796
          }
        },
        "0d0de53c6599467d97166effc9795179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f90a80724964946b7c233866859c346",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_84206d064d9a4116aae01b9a1d823b3f",
            "value": "â€‡2.80k/2.80kâ€‡[00:00&lt;00:00,â€‡81.6kB/s]"
          }
        },
        "4447087ff28d427eb30a654c438d850b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7896fa01c08497cba97982c01df7c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ac426e18bf4afeb2df764c50448ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f1c099d9234aaab6002f14330b0a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f261793ba73484a84a85c92c9aae4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f90a80724964946b7c233866859c346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84206d064d9a4116aae01b9a1d823b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "376d9f7b1e4044218f662b4f8cdda836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0751d2b5d3f344a1ba719241d16b9c65",
              "IPY_MODEL_df633e608ada4c7e8b8238cb221db739",
              "IPY_MODEL_76753b02dce24351af3e2296fb3f5e0c"
            ],
            "layout": "IPY_MODEL_2d24ffabd2f8417ba3f6b039b3014ab9"
          }
        },
        "0751d2b5d3f344a1ba719241d16b9c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d46474f7c24285a818352fdbc12a76",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b6401a11ba43431fa04a8dbd56af5438",
            "value": "model.bin:â€‡100%"
          }
        },
        "df633e608ada4c7e8b8238cb221db739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8907c806714278be338e3f9a78b132",
            "max": 3086912962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fdba297b1b24f06a2b9c5767b64a91e",
            "value": 3086912962
          }
        },
        "76753b02dce24351af3e2296fb3f5e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46d52861e235488b82aa0c6aa7c0fdbc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bc12ffae6ad943b6aed3c2251a24352f",
            "value": "â€‡3.09G/3.09Gâ€‡[00:18&lt;00:00,â€‡156MB/s]"
          }
        },
        "2d24ffabd2f8417ba3f6b039b3014ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d46474f7c24285a818352fdbc12a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6401a11ba43431fa04a8dbd56af5438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f8907c806714278be338e3f9a78b132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fdba297b1b24f06a2b9c5767b64a91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46d52861e235488b82aa0c6aa7c0fdbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc12ffae6ad943b6aed3c2251a24352f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}